
[TOC]

# 概述

## 直接内存存取

执行 IO 操作的技术有三种：可编程 IO、中断驱动 IO 和 直接内存存取（DMA）。

## 多道程序设计

假设内存空间容得下操作系统和两个用户程序，那么当一个作业需要等待 IO 时，处理器可以切换到另一个可能并不在等待 IO 的作业。

## 信息保护和安全

与操作系统相关的大多数安全和保护问题可分为 4 类：

- 可用性
- 保密性
- 数据完整性
- 认证

## 调度和资源管理

任何资源分配和调度策略都须考虑 3 个因素：

- 公平性
- 有差别的响应性
- 有效性

UNIX 是 C 语言编写的

# 进程管理

关于进程的定义，如下所示：

- 一个正在执行的程序
- 计算机中正在运行的程序的一个实例
- 可分配给处理器并由处理器执行的一个实体
- 由一个单一顺序线程、一个当前状态和一组相关的系统资源所表征的活动单元。

进程由三部分组成：

- 一段可执行的程序
- 程序所需要的相关数据（变量、工作区间、缓冲区间）
- 程序的执行上下文（execution context）

执行上下文又称为进程状态，是操作系统用来管理和控制进程所需的内部数据。

产生错误的主要原因：

- 不正确的同步
- 失败的互斥
- 不确定的程序操作
- 死锁

## 进程

进程的两个基本元素是程序代码和与代码相关联的数据集。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

PCB 包括**标识符，状态，优先级，程序计数器，内存指针，IO状态信息**等。

### 进程5状态模型

- 创建态
- 就绪态
- 运行态
- 阻塞态
- 终止态


![](image/ProcessState.png)

### 调度算法

## 线程

一个进程中可能有一个或多个线程，每个线程都有：

- 一个线程执行状态
- 未运行时保存的线程上下文；线程可视为在进程内运行的一个独立程序计数器
- 一个执行栈
- 每个线程用于局部变量的一些静态存储空间
- 与进程内其他线程共享的内存和资源的访问

比较性能后会发现线程有如下优点：

- 创建新线程的时间远少于创建一个全新进程的时间。
- 终止线程要比终止进程所花的时间横扫
- 同一进程内线程间切换的时间要少于进程间切换的时间
- 线程提高了不同执行程序间通信的效率。独立进程间的通信需要内核介入，而同一进程中的多个线程共享内存和文件，因此无需调用内核就可互相通信。

线程分为两大类，即用户级线程（ULT）和内核机线程（KLT），后者又称内核支持的线程或轻量级进程。

在纯ULT软件中，管理线程的所有工作都由应用程序完成，内核意识不到线程的存在。在纯KLT软件中，管理线程的所有工作均由内核完成，应用级没有线程管理代码，只有一个到内核线程设施的应用编程借口，Windows是这种方法的一个例子。

ULT线程切换不需要内核模式特权，不会乱底层的操作系统调度程序，可在任何操作系统中运行，不需要对底层内核进程修改以支持ULT。

在ULT执行一个系统调用时，不仅会阻塞这个线程，也会阻塞进程中的所有线程；在纯ULT策略中，多线程应用程序不能利用多核处理技术。

## 并发性：互斥和同步

- 原子操作

  一个函数或动作由一个或多个指令的序列实现，对外是不可见的；也就是说，没有其他进程可以看到其中间状态或能中断此操作。原子性保证了并发进程的隔离。

- 临界区

  一段代码，在这段代码中进程将访问共享资源，当另外一个进程已在这段代码中运行时，这个进程就不能在这段代码中执行。

- 死锁

  两个或两个以上的进程因每个进程都在等待其他进程做完某些事情而不能继续执行的情况

- 活锁

  两个或两个以上的进程为响应其他进程中的变化而持续改变子集的状态但不做有用的工作的情况

- 互斥

  当一个进程在临界区访问共享资源时，其他进程不能进入该临界区访问任何共享资源的情况

- 竞争条件

  多个线程或进程在读写一个共享数据时，结果依赖于它们执行的相对时间的情况

- 饥饿

  一个可运行的进程尽管能继续执行，但被调度程序无限期地忽视，而不能被调度执行的情况

### 互斥的要求

- 必须强制实施互斥，在与相同资源或共享对象的临界区有关的所有进程中，一次只允许一个进程进入临界区。
- 一个在非临界区停止的进程不能干涉其他进程
- 绝不允许出现需要访问临界区的进程被无限延迟的情况，即不会死锁或饥饿
- 一个进程驻留在临界区的时间必须是有限的

实现互斥的硬件方法：

- 中断禁用

  代价高，有时并不能保证互斥

- 专用机器指令

  一些机器指令，用于保证两个动作的原子性，如在一个取指周期中对一个存储器单元的读和写或读和测试。在这个指令执行的过程中，任何其他指令访问内存都将被阻止，而且这些动作在一个指令周期中完成。

### 信号量

用于进程间传递信号的一个整数值。在信号量上只可进行三种操作，即初始化、递减和递增。二元信号量是只取0值和1值的信号量。

设有n个进程，用数组P(i)表示，所有进程都需要访问共享资源。每个进程进入临界区前执行semWait(s)，若s的值为负，则进程被阻塞；若值为1，则s被减为0，进程立即进入临界区；由于s不再为正，因而其他任何进程都不能进入临界区。

### 管程

管程是由一个或多个进程、一个初始化序列和局部数据组成的软件模块，其主要特点如下:

- 局部数据变量只能被管程的过程访问，任何外部过程都不能访问
- 一个进程通过调用管程的一个过程进入管程
- 在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都会被阻塞，以等待管程可用

管程通过使用条件变量来支持同步，这些条件变量包含在管程中，并且只有在管程中才能被访问。

### 消息传递

进程交互时，必须满足两个基本要求：同步和通信。为了实施互斥，进程间需要同步；为实现合作，进程间需要交换信息。提供这些功能的一种方法就是消息传递。

## 并发：死锁和饥饿

死锁有三个必要条件：

- 互斥。一次只有一个进程可以使用一个资源，其他进程不能访问已分配给其他进程的资源。
- 占有且等待。当一个进程等待其他进程时，继续占有已分配的资源。
- 不可抢占。不能强行抢占进程已占有的资源。

例如，要确保结果的一致性和数据库的完整性，互斥时非常有必要的。同理，不能随意地进行资源抢占。比如，在涉及数据资源时，必须提供回滚恢复机制来支持资源抢占，只有这样才能把进程及其资源恢复到以前的适当状态，使得进程最终可以重复其动作。

要产生死锁，还需要第四个条件：

- 循环等待。存在一个闭合的进程链，每个进程至少占有此链中下一个进程所需的一个资源。

处理死锁的方法有三种：

- 死锁预防。采用某种策略消除四个条件的某个条件的出现，来预防死锁。
- 死锁避免。基于资源分配的当前状态做动态选择来避免死锁。
- 死锁检测。试图检测死锁的存在并从死锁中恢复。

### 死锁预防

死锁预防方法分为两类：

- 间接死锁预防方法，即防止前三个必要条件中的任意一个条件的发生。
- 直接死锁预防，即防止循环等待的发生。

对于互斥，不可能禁止。不过某些资源，如文件，可能允许多个读访问，但只能允许互斥的写访问，此时若有多个进程请求写权限，则也可能发生死锁。

为预防占有且等待条件，可以要求进程一次性地请求所有需要的资源，并阻塞这个进程直到所有请求都同时满足。

预防不可抢占的方法有几种。首先，占有某些资源的一个进程进一步申请资源时若被拒绝，则该进程必须释放其最初占有的资源，必要时可再次申请这些资源和其他资源。其次，一个进程请求当前被另一个进程占有的一个资源时，操作系统可以抢占另一个进程，要求它释放资源。

循环等待条件可通过定义资源类型的线性顺序来预防。若一个进程已分配了R类型的资源，则其接下来请求的资源只能是那些排在R类型之后的资源。

### 死锁避免

两种死锁避免方法：

- 若一个进程的请求会导致死锁，则不会启动该进程
- 若一个进程增加的资源请求会导致死锁，则不允许这一资源分配

资源分配拒绝测策略，又称为银行家算法。类似于银行业务。重银行贷款的顾客对应于进程，贷出的钱对应于资源。作为银行业务问题，银行能贷出的钱有限，每名顾客都有一定的银行信用额。顾客可以选择借一部分，但不能保证顾客取得大量贷款后一定能偿还。银行没有足够的本金放贷时，银行也会拒绝贷款给顾客。

死锁避免的优点是，无须死锁预防中的抢占和回滚进程，且与死锁预防相比限制减少。但是，它在使用中也有许多限制：

- 必须事先申明每个进程请求的最大资源
- 所讨论的进程必须是无关的，即它们的执行顺序必须没有任何同步要求的限制。
- 分配的资源数量必须是固定的。
- 在占有资源时，进程不能退出。

### 死锁检测

检测死锁算法的基本思想是：

	获得某时刻 t 系统中各类可利用资源的数目向量 available(t)，对于系统中的一组进程{$P_1$,$P_1$,$\dots$,$P_n$}，找出哪些对各类资源请求数目均小于系统现有的各类可利用资源数目的进程。这样的进程可以获得它们所需要的全部资源并运行结束，当运行结束后，它们会释放所占有的全部资源，从而使可用资源数目增加，将这样的进程加入到可运行结束的进程序列中，然后对剩下的进程再进程上述考查。

检测死锁后，需要某种策略恢复死锁。下面按复杂度递增的顺序列出可能的方法：

1. 取消所有的死锁进程。
2. 把每个死锁进程回滚到前面定义的某些检查点，并重新启动所有进程。
3. 连续取消死锁进程直到不再存在死锁。
4. 连续抢占资源直到不再存在死锁。

### 哲学家就餐问题

一张圆桌上有一大碗面和5个盘子，每位哲学家一个盘子，还有5把叉子。每位想吃饭的哲学家将坐到桌子旁分配给他的位置，使用盘子两侧的叉子，取面和吃面，且每位哲学家需要两把叉子来吃意大利面条。

问题是：设计一套哲学家吃饭的礼仪（算法）。算法必须保证互斥（两位哲学家不能同时使用同一把叉子），同时还要避免死锁和饥饿。

哲学家就餐问题可视为应用程序中包含并发执行的线程时，协调处理共享资源的代表性问题。

#### 基于信号量的解决方案

每位哲学家首先拿起左边的叉子，然后拿起右边的叉子。在哲学家吃完面后，这两把叉子又被放回到餐桌上。如果所有哲学家在同一时刻都感到饥饿，这个解决方案会导致死锁。为了避免死锁的危险，考虑增加一位服务员，他只允许4位哲学家同时进入餐厅。

#### 基于管程的解决方案

定义一个含有5个条件变量的向量，每把叉子对应一个条件变量。用来标示哲学家等待的叉子可用情况。另外用一个布尔向量记录每把叉子的可用情况。管程包含了两个过程，get_forks 函数标示哲学家取他/她左边和右边的叉子。如果至少有一把叉子不可用，那么哲学家进程就会在条件变量的队列中等待。这样可让其他哲学家进程进入管程。release_forks 函数用来标示两把叉子可用。

### UNIX 并发机制

- 管道
- 信号量
- 消息
- 信号
- 共享内存

### Linux内核并发机制

除了所有UNIX出现的，还支持一种特殊类型的信号—实时信号，它与信号相比有三个主要不同点：

- 支持按优先级顺序排列的信号进行传递
- 多个信号能进行排队
- 在标准信号机制中数值和消息只能视为通知，不能发送给目标进程，但实时信号机制可以将数值随信号一起发送过去。

#### 原子操作

#### 自旋锁

### Windows 7 的并发机制

- 等待函数
- 分派器对象
- 临界区
- 轻量级读写锁和条件变量
- 锁无关同步机制

# 内存管理

操作系统担负着 5 项存储器管理职责：

- 进程隔离
- 自动分配和管理
- 支持模块化程序设计
- 保护和访问控制
- 长期存储

在分页系统中，进程由许多固定大小的块组成，这些块称为页。程序通过虚地址访问字，虚地址由页号和页中的偏移量组成。

## 应用程序的编译、链接与装入

应用程序从用户编写的源文件到内存中执行，大致分为3个阶段：

- 首先，经过编译程序将源代码编译为若干个目标模块
- 然后，通过链接程序将编译好的目标模块以及所需的库函数链接在一起，形成完整的装入模块
- 最后，通过装入程序将这些装入模块装入内存并执行。

源程序经过编译之后得到目标代码，由于编译程序无法得知代码驻留在内存中的实际位置（物理地址），一般总是从0号单元开始编址，并顺序分配所有地址单元，这些称为相对地址或者虚拟地址。

一个完整的程序可以由多个模块构成，这些模块都是从0号单元开始编址。当链接程序将多个模块链接装入模块时，链接程序会按照各个模块的相对地址将其地址构成统一的从0号单元开始编址的相对地址。

当装入程序将可执行代码装入内存时，程序的逻辑地址与程序在内存的实际地址通常不同，这就需要通过地址转换将逻辑地址换为物理地址，这个过程叫作重定位。

内存管理的需求如下：

- 重定位
- 保护
- 共享
- 逻辑组织
- 物理组织

## 分区

### 固定分区分配

它将内存空间分为若干个固定大小的分区，分区的大小可以不等。

- 分区大小相等。缺乏灵活性，造成内存空间浪费，当程序太大时，一个分区又不足以装入程序，导致程序无法运行。
- 分区大小不等。可把内存划分含有多个较小的分区、适量的中等分区及少量的大分区。

### 动态分区分配

- 优点

  实现了多道程序共用主存，管理方案相对简单、不需要更多开销，实现存储保护的手段比较简单。

- 缺点

  主存利用不够充分，存在外部碎片，无法实现多进程共享存储器信息，无法实现主存的扩充，进程地址空间受实际存储空间的限制。

#### 分区分配中的数据结构

- 空闲分区表
- 空闲分区链

#### 分区分配算法

- 首次适应算法

  把空闲分区按照地址递增的次序用链表串成一个队列，每次需要分配内存时都从队首开始找，直到找到足够大的空闲分区，否则分配失败。

  优点：优先利用内存低地址部分的空闲分区，从而保留了高地址部分的大的空闲分区，无内部碎片。

  缺点：使得地址端留下许多难以利用的很小的空闲分区（外部碎片），查找可用空闲分区的开销大。

- 下次适应算法

- 最佳适应算法

  要求将空闲分区按照容量大小递增的次序排列。每次为作业分配内存空间时，总是将能满足空间大小需要的最小的空闲分区分配给作业。这样可以产生最小的内存空闲区。

  优点：总能分配给作业最恰当的分区，并保留大的分区

  缺点：导致产生很多难以利用的碎片空间。

- 最差适应算法

### 分区分配的动态管理

#### 拼接技术

#### 动态重定位分区分配技术

## 分页

在分页存储管理中，用户作业的地址空间被划分成若干个大小相等的区域，称为页或页面。

为了将逻辑地址上连续的页号映射到物理内存中后称为离散分布的多个物理块，需要将每个页面和每个物理块一一对应，这种映射关系就体现在页表上。页表中每个页表项都由页号和块号组成。

基本分页存储管理方式的优缺点：

- 优点：内存利用率高，实现了离散分配，便于存储访问控制，无外部碎片
- 缺点：需要硬件支持，内存访问效率下降，共享困难，内部碎片

## 分段

在分段存储管理系统中，作业的地址空间由若干个逻辑分段组成，每个分段是一组逻辑意义上相对完整的信息集合，每个分段都有自己的名字，每个分段都从0开始编址，并采用一段连续的地址空间。

与分页存储管理类似，为了实现从逻辑地址到物理地址的变换，系统为每个进程建立一个段表，其中每个表项描述一个分段的信息，表项中包含段号、段长和该段的内存起始地址。

分段存储管理相较于分页存储管理有如下有优点：

- 方便编程：用户把自己的作业按照逻辑关系划分为若干个段，每段都是从0开始编址，有自己的名称和长度。
- 信息共享：页面是存放信息的物理单位，没有完整的意义；而段是信息的逻辑单位，用户可以把需要共享的部分代码和数据放在同一段以便信息共享。
- 信息保护：由于每一段都包含相对独立的信息，因此对信息保护可以采取对段进行保护，信息保护相对于分页式方便许多。

基本分段存储管理方式的优缺点

- 优点：便于程序模块化处理和处理变换的数据结构，便于动态链接和共享，无内部碎片。
- 缺点：需要硬件支持，要采用拼接技术，分段的最大尺寸受到主存可用空间的限制，有外部碎片。

## 段页式

用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。

用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。

程序对内存的调入或调出是按页进行的，但它又可按段实现共享和保护。

## 页面置换算法

### 最佳置换（OPT）算法

在预知一个进程的页面号引用串的情况下，每次都淘汰以后不在使用的或以后最迟再被使用的页面。但由于实际操作中往往无法事先知道以后引用到的所有页面的信息，因此最佳置换算法无法实现，只能作为一个标准来衡量其他置换算法的优劣。

### 先进先出（FIFO）算法

每次总是淘汰最先进入内存的页面，也就是淘汰在内存驻留时间最长的页面。不过FIFO算法可能会产生Belady异常，因为最早调入的页面往往是使用最频繁的页面，可能选择淘汰的页面是程序经常使用的页面，实际效果不好。

### 最近最少使用（LRU）算法

选择最近最长时间没有被使用的页面予以淘汰，其思想是用以前的页面引用情况来预测将来会出现的页面引用情况，也就是假设一个页面刚被访问，那么不久该页面还会被访问。

### Bleady 异常

缺页率可能会随着所分配的物理块数的增加而增加，这种奇怪的现象就是 Bleady 异常，例如，对于引用串1,2,3,4,1,2,5,1,2,3,4,5，内存中物理块数为3时发生9次缺页中断。

LRU 算法和最佳置换算法永远不会出现Bleady异常。

### 抖动现象

刚被淘汰的页面，过后不久又要访问，并且调入不久后又调出，如此反复，使得系统把大部分时间用在了页面的调入调出上，而几乎不能完成任何有效的工作，这种现象称为抖动。

### 缺页率

假定一个作业有n页，系统分配给该作业m页的空间。如果该作业在运行中共需要访问A次页面，其中所要访问页面不在内存，需要将所需页调入内存的次数为F，则缺页率定义为f=F/A，命中率即为1-f。

## 虚拟内存

在程序装入时，一方面可以将程序的一部分放入内存，而将其余部分放在外存，然后启动程序（部分装入）。在程序执行过程中，当所访问的信息不在内存中时，再由系统将所需的部分调入内存（请求调入）。另一方面，操作系统将内存中暂时不使用的内容置换到外存中，从而腾出空间存放将要调入内存的信息（置换功能）。这种从逻辑上扩充内存容量的存储器系统称为虚拟存储器。

# 单处理器调度

# 多处理器和实时调度

# 文件管理



# 设备管理

执行I/O的三种技术：

- 程序控制I/O：处理器代表一个进程给IO模块发送一个IO命令；该进程进入忙等待，直到操作完成才能继续执行。
- 中断驱动IO：处理器代表进程向IO模块发出一个IO命令。
- 直接存储器访问（DMA）：一个DMA模块控制内存和IO模块之间的数据交换。为传送一块数据，处理器给DMA模块发请求，且只有在整个数据块传送结束后，它才被中断。